{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/SNF-env/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "'''An implementation of sequence to sequence learning for performing addition\n",
    "\n",
    "Input: \"535+61\"\n",
    "Output: \"596\"\n",
    "Padding is handled by using a repeated sentinel character (space)\n",
    "\n",
    "Input may optionally be inverted, shown to increase performance in many tasks in:\n",
    "\"Learning to Execute\"\n",
    "http://arxiv.org/abs/1410.4615\n",
    "and\n",
    "\"Sequence to Sequence Learning with Neural Networks\"\n",
    "http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf\n",
    "Theoretically it introduces shorter term dependencies between source and target.\n",
    "\n",
    "Two digits inverted:\n",
    "+ One layer LSTM (128 HN), 5k training examples = 99% train/test accuracy in 55 epochs\n",
    "\n",
    "Three digits inverted:\n",
    "+ One layer LSTM (128 HN), 50k training examples = 99% train/test accuracy in 100 epochs\n",
    "\n",
    "Four digits inverted:\n",
    "+ One layer LSTM (128 HN), 400k training examples = 99% train/test accuracy in 20 epochs\n",
    "\n",
    "Five digits inverted:\n",
    "+ One layer LSTM (128 HN), 550k training examples = 99% train/test accuracy in 30 epochs\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "from six.moves import range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharacterTable(object):\n",
    "    \"\"\"Given a set of characters:\n",
    "    + Encode them to a one hot integer representation\n",
    "    + Decode the one hot integer representation to their character output\n",
    "    + Decode a vector of probabilities to their character output\n",
    "    \"\"\"\n",
    "    def __init__(self, chars):\n",
    "        \"\"\"Initialize character table.\n",
    "\n",
    "        # Arguments\n",
    "            chars: Characters that can appear in the input.\n",
    "        \"\"\"\n",
    "        self.chars = sorted(set(chars))\n",
    "        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))\n",
    "        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n",
    "\n",
    "    def encode(self, C, num_rows):\n",
    "        \"\"\"One hot encode given string C.\n",
    "\n",
    "        # Arguments\n",
    "            num_rows: Number of rows in the returned one hot encoding. This is\n",
    "                used to keep the # of rows for each data the same.\n",
    "        \"\"\"\n",
    "        x = np.zeros((num_rows, len(self.chars)))\n",
    "        for i, c in enumerate(C):\n",
    "            x[i, self.char_indices[c]] = 1\n",
    "        return x\n",
    "\n",
    "    def decode(self, x, calc_argmax=True):\n",
    "        if calc_argmax:\n",
    "            x = x.argmax(axis=-1)\n",
    "        return ''.join(self.indices_char[x] for x in x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class colors:\n",
    "    ok = '\\033[92m'\n",
    "    fail = '\\033[91m'\n",
    "    close = '\\033[0m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for the model and dataset.\n",
    "TRAINING_SIZE = 50000\n",
    "DIGITS = 3\n",
    "INVERT = True\n",
    "\n",
    "# Maximum length of input is 'int + int' (e.g., '345+678'). Maximum length of\n",
    "# int is DIGITS.\n",
    "MAXLEN = DIGITS + 1 + DIGITS\n",
    "\n",
    "# All the numbers, plus sign and space for padding.\n",
    "chars = '0123456789+ '\n",
    "ctable = CharacterTable(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating data...\n",
      "Total addition questions: 50000\n"
     ]
    }
   ],
   "source": [
    "questions = []\n",
    "expected = []\n",
    "seen = set()\n",
    "print('Generating data...')\n",
    "while len(questions) < TRAINING_SIZE:\n",
    "    f = lambda: int(''.join(np.random.choice(list('0123456789'))\n",
    "                    for i in range(np.random.randint(1, DIGITS + 1))))\n",
    "    a, b = f(), f()\n",
    "    # Skip any addition questions we've already seen\n",
    "    # Also skip any such that x+Y == Y+x (hence the sorting).\n",
    "    key = tuple(sorted((a, b)))\n",
    "    if key in seen:\n",
    "        continue\n",
    "    seen.add(key)\n",
    "    # Pad the data with spaces such that it is always MAXLEN.\n",
    "    q = '{}+{}'.format(a, b)\n",
    "    query = q + ' ' * (MAXLEN - len(q))\n",
    "    ans = str(a + b)\n",
    "    # Answers can be of maximum size DIGITS + 1.\n",
    "    ans += ' ' * (DIGITS + 1 - len(ans))\n",
    "    if INVERT:\n",
    "        # Reverse the query, e.g., '12+345  ' becomes '  543+21'. (Note the\n",
    "        # space used for padding.)\n",
    "        query = query[::-1]\n",
    "    questions.append(query)\n",
    "    expected.append(ans)\n",
    "print('Total addition questions:', len(questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80+598  = 678 \n",
      "6+782   = 788 \n",
      "5+19    = 24  \n",
      "81+714  = 795 \n",
      "13+40   = 53  \n",
      "335+10  = 345 \n",
      "5+695   = 700 \n",
      "0+40    = 40  \n",
      "90+84   = 174 \n",
      "176+76  = 252 \n"
     ]
    }
   ],
   "source": [
    "# Print example test data.\n",
    "# Note that questions are inverted in the training for better performance.\n",
    "for i in range(10):\n",
    "    print('%s = %s' %(questions[i][::-1],expected[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n"
     ]
    }
   ],
   "source": [
    "print('Vectorization...')\n",
    "x = np.zeros((len(questions), MAXLEN, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(questions), DIGITS + 1, len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(questions):\n",
    "    x[i] = ctable.encode(sentence, MAXLEN)\n",
    "for i, sentence in enumerate(expected):\n",
    "    y[i] = ctable.encode(sentence, DIGITS + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle (x, y) in unison as the later parts of x will almost all be larger\n",
    "# digits.\n",
    "indices = np.arange(len(y))\n",
    "np.random.shuffle(indices)\n",
    "x = x[indices]\n",
    "y = y[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explicitly set apart 10% for validation data that we never train over.\n",
    "split_at = len(x) - len(x) // 10\n",
    "(x_train, x_val) = x[:split_at], x[split_at:]\n",
    "(y_train, y_val) = y[:split_at], y[split_at:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:\n",
      "(45000, 7, 12)\n",
      "(45000, 4, 12)\n"
     ]
    }
   ],
   "source": [
    "print('Training Data:')\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Data:\n",
      "(5000, 7, 12)\n",
      "(5000, 4, 12)\n"
     ]
    }
   ],
   "source": [
    "print('Validation Data:')\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try replacing GRU, or SimpleRNN.\n",
    "RNN = layers.LSTM\n",
    "HIDDEN_SIZE = 128\n",
    "BATCH_SIZE = 128\n",
    "LAYERS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "model = Sequential()\n",
    "# \"Encode\" the input sequence using an RNN, producing an output of HIDDEN_SIZE.\n",
    "# Note: In a situation where your input sequences have a variable length,\n",
    "# use input_shape=(None, num_feature).\n",
    "model.add(RNN(HIDDEN_SIZE, input_shape=(MAXLEN, len(chars))))\n",
    "# As the decoder RNN's input, repeatedly provide with the last hidden state of\n",
    "# RNN for each time step. Repeat 'DIGITS + 1' times as that's the maximum\n",
    "# length of output, e.g., when DIGITS=3, max output is 999+999=1998.\n",
    "model.add(layers.RepeatVector(DIGITS + 1))\n",
    "# The decoder RNN could be multiple layers stacked or a single layer.\n",
    "for _ in range(LAYERS):\n",
    "    # By setting return_sequences to True, return not only the last output but\n",
    "    # all the outputs so far in the form of (num_samples, timesteps,\n",
    "    # output_dim). This is necessary as TimeDistributed in the below expects\n",
    "    # the first dimension to be the timesteps.\n",
    "    model.add(RNN(HIDDEN_SIZE, return_sequences=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 128)               72192     \n",
      "_________________________________________________________________\n",
      "repeat_vector_1 (RepeatVecto (None, 4, 128)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 4, 128)            131584    \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 4, 12)             1548      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 4, 12)             0         \n",
      "=================================================================\n",
      "Total params: 205,324\n",
      "Trainable params: 205,324\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Apply a dense layer to the every temporal slice of an input. For each of step\n",
    "# of the output sequence, decide which character should be chosen.\n",
    "model.add(layers.TimeDistributed(layers.Dense(len(chars))))\n",
    "model.add(layers.Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_iter=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 16s 348us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0027 - val_acc: 0.9996\n",
      "Q 111+289 T 400  \u001b[92m☑\u001b[0m 400 \n",
      "Q 4+663   T 667  \u001b[92m☑\u001b[0m 667 \n",
      "Q 331+54  T 385  \u001b[92m☑\u001b[0m 385 \n",
      "Q 10+201  T 211  \u001b[92m☑\u001b[0m 211 \n",
      "Q 777+324 T 1101 \u001b[92m☑\u001b[0m 1101\n",
      "Q 9+693   T 702  \u001b[92m☑\u001b[0m 702 \n",
      "Q 470+75  T 545  \u001b[92m☑\u001b[0m 545 \n",
      "Q 999+571 T 1570 \u001b[92m☑\u001b[0m 1570\n",
      "Q 72+883  T 955  \u001b[92m☑\u001b[0m 955 \n",
      "Q 13+983  T 996  \u001b[92m☑\u001b[0m 996 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 16s 349us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0027 - val_acc: 0.9995\n",
      "Q 2+206   T 208  \u001b[92m☑\u001b[0m 208 \n",
      "Q 5+731   T 736  \u001b[92m☑\u001b[0m 736 \n",
      "Q 690+50  T 740  \u001b[92m☑\u001b[0m 740 \n",
      "Q 8+439   T 447  \u001b[92m☑\u001b[0m 447 \n",
      "Q 63+236  T 299  \u001b[92m☑\u001b[0m 299 \n",
      "Q 78+902  T 980  \u001b[92m☑\u001b[0m 980 \n",
      "Q 77+12   T 89   \u001b[92m☑\u001b[0m 89  \n",
      "Q 50+953  T 1003 \u001b[92m☑\u001b[0m 1003\n",
      "Q 4+200   T 204  \u001b[92m☑\u001b[0m 204 \n",
      "Q 461+632 T 1093 \u001b[92m☑\u001b[0m 1093\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 3\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 15s 340us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0026 - val_acc: 0.9994\n",
      "Q 6+899   T 905  \u001b[92m☑\u001b[0m 905 \n",
      "Q 10+0    T 10   \u001b[92m☑\u001b[0m 10  \n",
      "Q 780+0   T 780  \u001b[92m☑\u001b[0m 780 \n",
      "Q 34+938  T 972  \u001b[92m☑\u001b[0m 972 \n",
      "Q 2+653   T 655  \u001b[92m☑\u001b[0m 655 \n",
      "Q 5+318   T 323  \u001b[92m☑\u001b[0m 323 \n",
      "Q 301+325 T 626  \u001b[92m☑\u001b[0m 626 \n",
      "Q 247+68  T 315  \u001b[92m☑\u001b[0m 315 \n",
      "Q 679+88  T 767  \u001b[92m☑\u001b[0m 767 \n",
      "Q 97+208  T 305  \u001b[92m☑\u001b[0m 305 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 4\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 15s 328us/step - loss: 9.1471e-04 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 0.9992\n",
      "Q 238+492 T 730  \u001b[92m☑\u001b[0m 730 \n",
      "Q 146+75  T 221  \u001b[92m☑\u001b[0m 221 \n",
      "Q 41+653  T 694  \u001b[92m☑\u001b[0m 694 \n",
      "Q 225+82  T 307  \u001b[92m☑\u001b[0m 307 \n",
      "Q 302+89  T 391  \u001b[92m☑\u001b[0m 391 \n",
      "Q 98+716  T 814  \u001b[92m☑\u001b[0m 814 \n",
      "Q 91+286  T 377  \u001b[92m☑\u001b[0m 377 \n",
      "Q 244+76  T 320  \u001b[92m☑\u001b[0m 320 \n",
      "Q 866+699 T 1565 \u001b[92m☑\u001b[0m 1565\n",
      "Q 48+839  T 887  \u001b[92m☑\u001b[0m 887 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 5\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 15s 331us/step - loss: 0.0475 - acc: 0.9871 - val_loss: 0.0115 - val_acc: 0.9970\n",
      "Q 252+305 T 557  \u001b[92m☑\u001b[0m 557 \n",
      "Q 247+166 T 413  \u001b[92m☑\u001b[0m 413 \n",
      "Q 917+114 T 1031 \u001b[92m☑\u001b[0m 1031\n",
      "Q 452+8   T 460  \u001b[92m☑\u001b[0m 460 \n",
      "Q 951+577 T 1528 \u001b[92m☑\u001b[0m 1528\n",
      "Q 773+672 T 1445 \u001b[92m☑\u001b[0m 1445\n",
      "Q 852+412 T 1264 \u001b[92m☑\u001b[0m 1264\n",
      "Q 1+772   T 773  \u001b[92m☑\u001b[0m 773 \n",
      "Q 587+609 T 1196 \u001b[92m☑\u001b[0m 1196\n",
      "Q 774+0   T 774  \u001b[92m☑\u001b[0m 774 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 6\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 15s 335us/step - loss: 0.0034 - acc: 0.9996 - val_loss: 0.0036 - val_acc: 0.9995\n",
      "Q 910+54  T 964  \u001b[92m☑\u001b[0m 964 \n",
      "Q 257+472 T 729  \u001b[92m☑\u001b[0m 729 \n",
      "Q 982+338 T 1320 \u001b[92m☑\u001b[0m 1320\n",
      "Q 3+443   T 446  \u001b[92m☑\u001b[0m 446 \n",
      "Q 559+218 T 777  \u001b[92m☑\u001b[0m 777 \n",
      "Q 2+479   T 481  \u001b[92m☑\u001b[0m 481 \n",
      "Q 487+261 T 748  \u001b[92m☑\u001b[0m 748 \n",
      "Q 49+80   T 129  \u001b[92m☑\u001b[0m 129 \n",
      "Q 22+93   T 115  \u001b[92m☑\u001b[0m 115 \n",
      "Q 814+13  T 827  \u001b[92m☑\u001b[0m 827 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 7\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 15s 339us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 0.9994\n",
      "Q 75+743  T 818  \u001b[92m☑\u001b[0m 818 \n",
      "Q 431+65  T 496  \u001b[92m☑\u001b[0m 496 \n",
      "Q 758+9   T 767  \u001b[92m☑\u001b[0m 767 \n",
      "Q 61+50   T 111  \u001b[92m☑\u001b[0m 111 \n",
      "Q 872+15  T 887  \u001b[92m☑\u001b[0m 887 \n",
      "Q 27+75   T 102  \u001b[92m☑\u001b[0m 102 \n",
      "Q 563+7   T 570  \u001b[92m☑\u001b[0m 570 \n",
      "Q 2+835   T 837  \u001b[92m☑\u001b[0m 837 \n",
      "Q 911+134 T 1045 \u001b[92m☑\u001b[0m 1045\n",
      "Q 642+851 T 1493 \u001b[92m☑\u001b[0m 1493\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 8\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 15s 329us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 0.9996\n",
      "Q 98+407  T 505  \u001b[92m☑\u001b[0m 505 \n",
      "Q 101+15  T 116  \u001b[92m☑\u001b[0m 116 \n",
      "Q 767+666 T 1433 \u001b[92m☑\u001b[0m 1433\n",
      "Q 388+78  T 466  \u001b[92m☑\u001b[0m 466 \n",
      "Q 11+980  T 991  \u001b[92m☑\u001b[0m 991 \n",
      "Q 87+747  T 834  \u001b[92m☑\u001b[0m 834 \n",
      "Q 21+796  T 817  \u001b[92m☑\u001b[0m 817 \n",
      "Q 871+6   T 877  \u001b[92m☑\u001b[0m 877 \n",
      "Q 50+408  T 458  \u001b[92m☑\u001b[0m 458 \n",
      "Q 305+14  T 319  \u001b[92m☑\u001b[0m 319 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 9\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 15s 332us/step - loss: 9.1125e-04 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 0.9998\n",
      "Q 48+209  T 257  \u001b[92m☑\u001b[0m 257 \n",
      "Q 7+843   T 850  \u001b[92m☑\u001b[0m 850 \n",
      "Q 28+153  T 181  \u001b[92m☑\u001b[0m 181 \n",
      "Q 253+8   T 261  \u001b[92m☑\u001b[0m 261 \n",
      "Q 963+42  T 1005 \u001b[92m☑\u001b[0m 1005\n",
      "Q 40+671  T 711  \u001b[92m☑\u001b[0m 711 \n",
      "Q 635+80  T 715  \u001b[92m☑\u001b[0m 715 \n",
      "Q 798+925 T 1723 \u001b[92m☑\u001b[0m 1723\n",
      "Q 11+219  T 230  \u001b[92m☑\u001b[0m 230 \n",
      "Q 42+2    T 44   \u001b[92m☑\u001b[0m 44  \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 10\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 15s 330us/step - loss: 8.3740e-04 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 0.9996\n",
      "Q 69+91   T 160  \u001b[92m☑\u001b[0m 160 \n",
      "Q 148+46  T 194  \u001b[92m☑\u001b[0m 194 \n",
      "Q 473+913 T 1386 \u001b[92m☑\u001b[0m 1386\n",
      "Q 232+853 T 1085 \u001b[92m☑\u001b[0m 1085\n",
      "Q 56+42   T 98   \u001b[92m☑\u001b[0m 98  \n",
      "Q 74+263  T 337  \u001b[92m☑\u001b[0m 337 \n",
      "Q 42+25   T 67   \u001b[92m☑\u001b[0m 67  \n",
      "Q 108+1   T 109  \u001b[92m☑\u001b[0m 109 \n",
      "Q 943+41  T 984  \u001b[92m☑\u001b[0m 984 \n",
      "Q 958+70  T 1028 \u001b[92m☑\u001b[0m 1028\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 11\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 15s 342us/step - loss: 0.0163 - acc: 0.9956 - val_loss: 0.1951 - val_acc: 0.9382\n",
      "Q 731+56  T 787  \u001b[92m☑\u001b[0m 787 \n",
      "Q 33+18   T 51   \u001b[92m☑\u001b[0m 51  \n",
      "Q 391+857 T 1248 \u001b[92m☑\u001b[0m 1248\n",
      "Q 843+730 T 1573 \u001b[91m☒\u001b[0m 1473\n",
      "Q 622+29  T 651  \u001b[92m☑\u001b[0m 651 \n",
      "Q 416+550 T 966  \u001b[92m☑\u001b[0m 966 \n",
      "Q 436+548 T 984  \u001b[91m☒\u001b[0m 884 \n",
      "Q 88+992  T 1080 \u001b[92m☑\u001b[0m 1080\n",
      "Q 652+95  T 747  \u001b[92m☑\u001b[0m 747 \n",
      "Q 254+89  T 343  \u001b[92m☑\u001b[0m 343 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 12\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 15s 338us/step - loss: 0.0194 - acc: 0.9942 - val_loss: 0.0040 - val_acc: 0.9994\n",
      "Q 741+2   T 743  \u001b[92m☑\u001b[0m 743 \n",
      "Q 4+551   T 555  \u001b[92m☑\u001b[0m 555 \n",
      "Q 477+935 T 1412 \u001b[92m☑\u001b[0m 1412\n",
      "Q 3+711   T 714  \u001b[92m☑\u001b[0m 714 \n",
      "Q 280+844 T 1124 \u001b[92m☑\u001b[0m 1124\n",
      "Q 881+95  T 976  \u001b[92m☑\u001b[0m 976 \n",
      "Q 77+12   T 89   \u001b[92m☑\u001b[0m 89  \n",
      "Q 5+810   T 815  \u001b[92m☑\u001b[0m 815 \n",
      "Q 385+715 T 1100 \u001b[92m☑\u001b[0m 1100\n",
      "Q 923+165 T 1088 \u001b[92m☑\u001b[0m 1088\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 13\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 15s 339us/step - loss: 0.0016 - acc: 0.9999 - val_loss: 0.0027 - val_acc: 0.9996\n",
      "Q 18+56   T 74   \u001b[92m☑\u001b[0m 74  \n",
      "Q 844+735 T 1579 \u001b[92m☑\u001b[0m 1579\n",
      "Q 759+8   T 767  \u001b[92m☑\u001b[0m 767 \n",
      "Q 7+78    T 85   \u001b[92m☑\u001b[0m 85  \n",
      "Q 642+169 T 811  \u001b[92m☑\u001b[0m 811 \n",
      "Q 64+930  T 994  \u001b[92m☑\u001b[0m 994 \n",
      "Q 264+39  T 303  \u001b[92m☑\u001b[0m 303 \n",
      "Q 956+1   T 957  \u001b[92m☑\u001b[0m 957 \n",
      "Q 150+901 T 1051 \u001b[92m☑\u001b[0m 1051\n",
      "Q 43+39   T 82   \u001b[92m☑\u001b[0m 82  \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 14\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 15s 342us/step - loss: 9.2197e-04 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 0.9996\n",
      "Q 402+864 T 1266 \u001b[92m☑\u001b[0m 1266\n",
      "Q 77+299  T 376  \u001b[92m☑\u001b[0m 376 \n",
      "Q 618+126 T 744  \u001b[92m☑\u001b[0m 744 \n",
      "Q 549+14  T 563  \u001b[92m☑\u001b[0m 563 \n",
      "Q 157+81  T 238  \u001b[92m☑\u001b[0m 238 \n",
      "Q 10+621  T 631  \u001b[92m☑\u001b[0m 631 \n",
      "Q 734+35  T 769  \u001b[92m☑\u001b[0m 769 \n",
      "Q 932+35  T 967  \u001b[92m☑\u001b[0m 967 \n",
      "Q 165+89  T 254  \u001b[92m☑\u001b[0m 254 \n",
      "Q 811+5   T 816  \u001b[92m☑\u001b[0m 816 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 15\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45000/45000 [==============================] - 15s 335us/step - loss: 7.7990e-04 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 0.9997\n",
      "Q 334+219 T 553  \u001b[92m☑\u001b[0m 553 \n",
      "Q 6+899   T 905  \u001b[92m☑\u001b[0m 905 \n",
      "Q 573+83  T 656  \u001b[92m☑\u001b[0m 656 \n",
      "Q 442+60  T 502  \u001b[92m☑\u001b[0m 502 \n",
      "Q 884+40  T 924  \u001b[92m☑\u001b[0m 924 \n",
      "Q 303+0   T 303  \u001b[92m☑\u001b[0m 303 \n",
      "Q 547+69  T 616  \u001b[92m☑\u001b[0m 616 \n",
      "Q 96+684  T 780  \u001b[92m☑\u001b[0m 780 \n",
      "Q 6+491   T 497  \u001b[92m☑\u001b[0m 497 \n",
      "Q 683+2   T 685  \u001b[92m☑\u001b[0m 685 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 16\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 15s 328us/step - loss: 7.2328e-04 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 0.9997\n",
      "Q 245+66  T 311  \u001b[92m☑\u001b[0m 311 \n",
      "Q 639+77  T 716  \u001b[92m☑\u001b[0m 716 \n",
      "Q 33+86   T 119  \u001b[92m☑\u001b[0m 119 \n",
      "Q 705+39  T 744  \u001b[92m☑\u001b[0m 744 \n",
      "Q 6+569   T 575  \u001b[92m☑\u001b[0m 575 \n",
      "Q 616+20  T 636  \u001b[92m☑\u001b[0m 636 \n",
      "Q 835+5   T 840  \u001b[92m☑\u001b[0m 840 \n",
      "Q 342+980 T 1322 \u001b[92m☑\u001b[0m 1322\n",
      "Q 746+188 T 934  \u001b[92m☑\u001b[0m 934 \n",
      "Q 9+621   T 630  \u001b[92m☑\u001b[0m 630 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 17\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 15s 330us/step - loss: 7.0178e-04 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 0.9996\n",
      "Q 29+15   T 44   \u001b[92m☑\u001b[0m 44  \n",
      "Q 132+180 T 312  \u001b[92m☑\u001b[0m 312 \n",
      "Q 435+86  T 521  \u001b[92m☑\u001b[0m 521 \n",
      "Q 928+236 T 1164 \u001b[92m☑\u001b[0m 1164\n",
      "Q 78+964  T 1042 \u001b[92m☑\u001b[0m 1042\n",
      "Q 95+3    T 98   \u001b[92m☑\u001b[0m 98  \n",
      "Q 530+430 T 960  \u001b[92m☑\u001b[0m 960 \n",
      "Q 17+300  T 317  \u001b[92m☑\u001b[0m 317 \n",
      "Q 961+4   T 965  \u001b[92m☑\u001b[0m 965 \n",
      "Q 316+94  T 410  \u001b[92m☑\u001b[0m 410 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 18\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 15s 343us/step - loss: 6.0436e-04 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 0.9997\n",
      "Q 314+468 T 782  \u001b[92m☑\u001b[0m 782 \n",
      "Q 45+967  T 1012 \u001b[92m☑\u001b[0m 1012\n",
      "Q 80+687  T 767  \u001b[92m☑\u001b[0m 767 \n",
      "Q 57+831  T 888  \u001b[92m☑\u001b[0m 888 \n",
      "Q 921+62  T 983  \u001b[92m☑\u001b[0m 983 \n",
      "Q 825+179 T 1004 \u001b[92m☑\u001b[0m 1004\n",
      "Q 255+36  T 291  \u001b[92m☑\u001b[0m 291 \n",
      "Q 465+57  T 522  \u001b[92m☑\u001b[0m 522 \n",
      "Q 177+893 T 1070 \u001b[92m☑\u001b[0m 1070\n",
      "Q 286+374 T 660  \u001b[92m☑\u001b[0m 660 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 19\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 15s 341us/step - loss: 0.0349 - acc: 0.9894 - val_loss: 0.0082 - val_acc: 0.9981\n",
      "Q 563+7   T 570  \u001b[92m☑\u001b[0m 570 \n",
      "Q 711+86  T 797  \u001b[92m☑\u001b[0m 797 \n",
      "Q 275+924 T 1199 \u001b[92m☑\u001b[0m 1199\n",
      "Q 77+223  T 300  \u001b[92m☑\u001b[0m 300 \n",
      "Q 98+979  T 1077 \u001b[92m☑\u001b[0m 1077\n",
      "Q 20+61   T 81   \u001b[92m☑\u001b[0m 81  \n",
      "Q 97+626  T 723  \u001b[92m☑\u001b[0m 723 \n",
      "Q 294+258 T 552  \u001b[92m☑\u001b[0m 552 \n",
      "Q 2+720   T 722  \u001b[92m☑\u001b[0m 722 \n",
      "Q 220+97  T 317  \u001b[92m☑\u001b[0m 317 \n"
     ]
    }
   ],
   "source": [
    "# Train the model each generation and show predictions against the validation\n",
    "# dataset.\n",
    "for iteration in range(1, no_iter):\n",
    "    print()\n",
    "    print('-' * 50)\n",
    "    print('Iteration', iteration)\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=BATCH_SIZE,\n",
    "              epochs=1,\n",
    "              validation_data=(x_val, y_val))\n",
    "    # Select 10 samples from the validation set at random so we can visualize\n",
    "    # errors.\n",
    "    for i in range(10):\n",
    "        ind = np.random.randint(0, len(x_val))\n",
    "        rowx, rowy = x_val[np.array([ind])], y_val[np.array([ind])]\n",
    "        preds = model.predict_classes(rowx, verbose=0)\n",
    "        q = ctable.decode(rowx[0])\n",
    "        correct = ctable.decode(rowy[0])\n",
    "        guess = ctable.decode(preds[0], calc_argmax=False)\n",
    "        print('Q', q[::-1] if INVERT else q, end=' ')\n",
    "        print('T', correct, end=' ')\n",
    "        if correct == guess:\n",
    "            print(colors.ok + '☑' + colors.close, end=' ')\n",
    "        else:\n",
    "            print(colors.fail + '☒' + colors.close, end=' ')\n",
    "        print(guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('rnn_model_%siter.h5' %no_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
